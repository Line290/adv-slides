<!doctype html>
<html>
<head>
    <meta charset="utf-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0, maximum-scale=1.0, user-scalable=no">

    <title>浅谈对抗样本</title>

    <link rel="stylesheet" href="css/reveal.css">
    <link rel="stylesheet" href="css/theme/night.css">

    <!-- Theme used for syntax highlighting of code -->
    <link rel="stylesheet" href="lib/css/zenburn.css">

    <!-- Printing and PDF exports -->
    <script>
        var link = document.createElement('link');
        link.rel = 'stylesheet';
        link.type = 'text/css';
        link.href = window.location.search.match(/print-pdf/gi) ? 'css/print/pdf.css' : 'css/print/paper.css';
        document.getElementsByTagName('head')[0].appendChild(link);
    </script>
    <style>
        h3 {
            font-size: 30px;
        }
    </style>
</head>
<body>
<div class="reveal">
    <div class="slides">
        <section data-background-transition="zoom">
            <section data-background-transition="zoom">
                <h2>浅谈对抗样本</h2>
                <hr>

                <p style="position: relative;left: 20%;margin-top: 10%;">林大权</p>
                <p style="position: relative;left: 20%;margin-top: 10%;">2022-05-13</p>
                <aside class="notes">
                    大家好，我是林大权

                    今天我分享的内容是浅谈对抗样本
                </aside>
            </section>


            <section>
                <h3>什么是对抗样本</h3>
                <img src="https://i.loli.net/2021/04/09/vlPjhFe9CMTAbRu.png" style="width: 800px;height: 400px;"
                     width="640px" height="480px">
                <p class="fragment" style="font-size: 30px;">精心设计的微小扰动，人眼几乎无法察觉，但是模型会将扰动后的图片识别错</p>
                <aside class="notes">
                    比如这个实验，针对输入的图像x我们可以识别出他57%是个熊猫

                    但是一旦加了一点噪声之后，加完之后的图像我们人眼还是能看出来是个熊猫

                    但是我们的模型居然把它识别成了一只长臂猿。

                    这个加了特殊设计噪声的图片就是对抗样本。


                </aside>
            </section>

            <section>
                <h3>人工智能——万物互联的时代</h3>
                <hr>
                <img src="https://i.loli.net/2021/04/10/6dOH4YZW3yvPgRr.png"
                     style="width: 1000px;height: 500px;" width="800px" height="600px">
                <aside class="notes">
                    我们试想一下，如果将来真的像科幻片一样进入了人工智能万物互联的时代。

                    车都是自动驾驶的，人们都用VR或者AR来看手机。

                    车跟车之间的安全距离都是由人工智能来控制。

                    那么有没有什么隐患？
                </aside>
            </section>

            <section>
                <h3>无人驾驶场景</h3>
                <hr>
                <img src="https://i.loli.net/2021/04/09/r9jU1X8g4kHSf7h.png"
                     style="width: 1000px;height: 500px;" width="800px" height="600px">
                <aside class="notes">
                    现在的无人驾驶场景比如这有个指示牌告诉智能车停下的话，学图像处理的人应该明白，我们可以通过cnn对这幅图进行啊目标检测，怎么怎么招，那么神经网络真的就很安全吗？

                    如果被人恶意攻击添加噪声上去，让stop变成其他的怎么办？

                    所以由此引出一系列问题，现在以神经网络为根基的深度学习，在将来落地在人工智能时代其实有很多隐患的。

                    现在的神经网络鲁棒性都很差，特别依赖样本来学习。那么我们就需要研究更鲁棒能防御对抗样本攻击的模型。
                </aside>
            </section>

            <section>
                <h3>什么样的样本是好的对抗样本？</h3>
                <hr>
                <p class="fragment" style="font-size: 30px;">1. 能使模型识别错误。</p>
                <p class="fragment" style="font-size: 30px;">2. 相对于原始输入，所添加的扰动是微小的、自然的、融入原始物体的</p>
                <aside class="notes">
                    那么一个对抗样本要满足什么条件

                    读
                </aside>
            </section>
            

            <section>
                <h3>对抗样本之扰动贴纸</h3>
                <img src="https://s2.loli.net/2022/05/13/rvSEteLQpaybiWZ.png" style="width: 1000px;height: 500px;"
                     width="800px" height="600px">

                <aside class="notes">
                    对抗扰动贴纸，贴在香蕉图片上，模型将带有扰动贴纸的香蕉识别为烤箱。
                </aside>
            </section>

            <section>
                <h3>对抗样本之3D对抗样本</h3>
                <img src="https://s2.loli.net/2022/05/13/Xmi7kTxPzJ5oMUN.png" style="width: 1000px;height: 500px;"
                     width="800px" height="600px">

                <aside class="notes">
                    根据对抗攻击生成贴图，3D打印出带有特殊纹理的乌龟，识别模型将各个角度的乌龟图片识别为来福枪。
                </aside>
            </section>


            <section>
                <h3>如何制作对抗样本</h3>
                <hr>
                <h3 § style="font-size: 30px">
                    \[\begin{aligned}
                    max_{\Delta x\in \Omega }L(x+\Delta x,y;\Theta)
                    \end{aligned} \]
                </h3>
                <p  style="font-size: 30px;">利用梯度上升给输入图片添加扰动使模型loss增大</p>
                <!-- <h3 class="fragment" style="font-size: 30px">
                    \[\begin{aligned}
                    \Delta x &= ϵsign(∇_xL(x,y;θ)) \qquad \text{(ICLR2015 FGSM)}\\
                    \Delta x &= ϵ \frac {∇_xL(x,y;θ)}{||∇_xL(x,y;θ)||} \qquad \text{(ICLR2017 FGM)}
                    \end{aligned} \]
                </h3> -->
                </aside>
            </section>

            <section>
                <h3>攻击方法：FGSM (Fast Gradient Sign Method): ICLR2015</h3>
                <hr>
                <p  style="font-size: 30px;">单次迭代攻击</p>
                <pre><code data-trim style="max-height: 1003px;width: 900px;">
                    对于每个x:
                      1.计算输入图片x的前向loss、反向传播得到梯度∇_x;
                      2.根据梯度计算出扰动r=ϵsign(∇_x)，并添加到当前图片x上，
                        得到对抗样本x'=x+r，其中ϵ为添加的扰动大小，例如8/255。
			</code></pre>
                <aside class="notes">
                    介绍

                    伪代码如下：读
                </aside>
            </section>

            <section>
                <h3>攻击方法：PGD (Projected Gradient Descent): ICLR2018</h3>
                <hr>
                <p  style="font-size: 30px;">多次迭代攻击</p>
                <pre>
                    <code data-trim style="max-height: 1003px;width: 900px;">
                    对于输入图片x:
                        1.初始化设置对抗样本x' = x + 随机噪声
                        for 0 to t:
                            2.计算x'的前向loss、反向传播得到梯度∇_x'
                            3.根据梯度计算出扰动r=ϵ/steps*sign(∇_x')，
                              并添加到当前对抗样本上x'，即x' = x'+r
                            4.将x'中超出[x-ϵ, x+ϵ]且超出0-255像素值范围的值截断
                        5.得到最终的对抗样本x'
			</code>
        </pre>
                <aside class="notes">
                    在之后提出了PGD算法，认为FGM通过epsilon参数一下算出对抗扰动可能不是最优的。因此采用PGD进行了改进，多迭代了几次，慢慢找到最优的扰动。

                    伪代码如下：读

                    **最后更新参数只使用最后一个x+r算出来的梯度**。缺点就是会让训练变慢接近t倍
                </aside>
            </section>



            <section>
                <h3>如何防御对抗样本</h3>
                <hr>
                <p style="font-size: 30px;">1. 传统方法将输入图片进行预处理，先进行一些随机变换，例如缩放、裁剪、更换压缩率，破坏精心设计的扰动</p>
                <p style="font-size: 30px;">2. 对抗训练</p>
                <aside class="notes">
                    研究意义

                    读
                </aside>
            </section>

            <section>
                <h3>1. JPEG去噪</h3>
                <img src="https://s2.loli.net/2022/05/13/wfoPKlAQG743sbS.png" style="width: 1000px;height: 500px;"
                     width="800px" height="600px">
            </section>


            <!-- <section>
                <h3>研究意义</h3>
                <hr>
                <p style="font-size: 30px;">神经网络的线性特点很容易受到线性扰动的攻击</p>
                <p style="font-size: 30px;">可靠的人工智能应用场景需要很高的鲁棒性、安全性、可解释和可靠性</p>
                <aside class="notes">
                    研究意义

                    读
                </aside>
            </section> -->

            <section>
                <h3>对抗训练</h3>
                <hr>
                <p  style="font-size: 40px;">从数学的角度定义对抗训练</h3>
                <h3 § style="font-size: 30px">
                    \[\begin{aligned}
                    min_{\theta}\mathbb{E}_{(x,y)∼ D} [max_{\Delta x\in \Omega }L(x+\Delta x,y;\Theta)]
                    \end{aligned} \]
                </h3>
                <p  style="font-size: 30px;">通过给输入图片添加扰动进行梯度上升(增大loss)，在参数更新上进行梯度下降(减小loss)</p>
                <img src="https://s2.loli.net/2022/05/13/Ur5JLKD7ATNoEGP.png" style="width: 800px;height: 300px;"
                     width="600px" height="300px">
                <aside class="notes">
                    从数学定义角度，定义对抗训练的公式如下

                    解释公式

                    有一个难题是如何获取 delta x

                    sign 正数1负数-1 指的是 针对loss的输入x求偏导，得到梯度方向是正是负 乘以一个系数 得到。这个是GAN之父在ICLR2015论文上提出的 叫FGSM

                    而两年之后，他又提出改进，用sign寻找梯度方向太拘束，我直接求向量全方向上的梯度再乘以一个系数。
                </aside>
            </section>



            
            


            <!-- <section>
                <h3>两个优化方向：<br>得到更优的扰动 & 提升训练速度</h3>
                <hr>
                <p style="font-size: 30px;">FreeAT (Free Adversarial Training): NIPS2019</p>
                <p style="font-size: 30px;">YOPO (You Only Propagate Once): NIPS2019</p>
                <p style="font-size: 30px;">FreeLB (Free Large-Batch): ICLR2020</p>
                <aside class="notes">
                    然后接下来的研究就是围绕得到更优的扰动和提升训练速度

                    FreeAT 和YOPO 没有细看 不过多叙述了

                    FreeLB我看了一下他的论文
                </aside>
            </section> -->

            <!-- <section data-background-transition="zoom">
                <img src="https://i.loli.net/2021/04/10/y8Lez3XOJlmrIda.png" style="width: 10000px;height: 500px;">
                <aside class="notes">
                    他在去年的自然语言理解基准榜单上得到了第一名

                    就是用对抗训练的思想。现在排在了第十一是微软研究的。

                    然后在对话阅读理解数据集上也是采用这个对抗思想，能力首次超过人类。是追一科技，论文还没来得及看
                </aside>
            </section>

            <section data-background-transition="zoom">
                <img src="https://i.loli.net/2021/04/10/c9pz4Gml5QJPsDE.png" style="width: 10000px;height: 500px;">
                <aside class="notes">

                </aside>
            </section> -->
        </section>


        <section data-background-transition="zoom">
            <section data-background-transition="zoom">
                <h2>NLP 中的对抗样本</h2>
            </section>


            <!-- <section data-background-transition="zoom">
                <h3>NLP的对手</h3>
                <hr>
                <p style="font-size: 30px;">1. 黑盒环境下对embedding进行扰动(对手不是从样本进行攻击)</p>
                <p style="font-size: 30px;">2. 在输入中添加分散注意力的句子(人工)</p>
                <p style="font-size: 30px;">3. 用GANs将输入投影到潜在空间，并搜索接近原始的文本对手</p>
                <aside class="notes">
                    讲一下nlp中的对抗对手

                    读
                </aside>
            </section> -->


            <section data-background-transition="zoom">
                <h3>NLP中攻击示例</h3>
                <hr>
                <img src="https://i.loli.net/2021/04/09/daKoDQkv35hwmEP.png" style="width: 700px;height: 300px;">
                <p style="font-size: 30px;">近义词攻击、符号攻击、缩写攻击...</p>
                <p style="font-size: 30px;">离散化 攻击embedding层</p>
                <aside class="notes">
                    读

                    因为nlp的输入其实就是one-hot向量，如果针对onehot进行扰动，每个扰动的距离恒为根号2 ，也不满足对抗样本的要求，所以基本上都是在embedding层来做扰动的
                </aside>
            </section>


            <!-- <section>
                <h3>FreeLB Min-Max公式</h3>
                <hr>
                <h3 style="font-size: 30px">
                    \[\begin{aligned}
                    min_{\theta}\mathbb{E}_{(Z,y)∼ D ,{m∼M }} [\frac {1}{K}\sum_{t=0}^{K-1} max_{\delta_t\in \Omega_t
                    }L(f_{\theta}(x+\delta_t),y)]
                    \end{aligned} \]
                </h3>
                <pre><code data-trim style="max-height: 1003px;width: 900px;">
                    对于每个x:
                      1.通过均匀分布初始化r，梯度g为0
                      对于每步t=1...K:
                        2.根据x+r计算前后向，累计梯度g
                        3.更新r
                      4.根据g/K更新梯度
			    </code></pre>
                <aside class="notes">

                </aside>
            </section> -->

            <!-- <section>
                <h3>嵌入训练过程</h3>
                <hr>
                <img src="https://i.loli.net/2021/04/10/GLlxoKgC46bPJiF.png" style="width: 1000px;height: 500px;">
            </section> -->

            <!-- <section>
                <h3>实验对比</h3>
                <hr>
                <img src="https://i.loli.net/2021/04/10/WTh7O4Ui5YenzNM.png" style="width: 700px;height: 300px;">
                <aside class="notes">

                </aside>
            </section> -->

        </section>


        <!-- <section data-background-transition="zoom">
            <section data-background-transition="zoom">
                <h2>GNN 中的对抗攻击</h2>
                <aside class="notes">

                </aside>
            </section>
            <section data-background-transition="zoom">
                <h2>结构攻击 & 特征攻击</h2>
                <img src="https://i.loli.net/2021/04/10/euEiCdStPJRWypk.png" style="width: 700px;height: 300px;">
                <h3 style="font-size: 30px">
                    \[\begin{aligned}
                    G(A,X）
                    \end{aligned} \]
                </h3>
                <p class="fragment" style="font-size: 30px;">场景：金融诈骗伪装</p>
                <aside class="notes">
                    然后是现在新兴的神经网络主流图神经网络

                    现在用GNN做认知推理是越来越常见的趋势

                    针对非欧空间的离散数据，也是相当容易被攻击的毒害的。
                </aside>
            </section>
        </section> -->

        <section data-background-transition="zoom">
            <section data-background-transition="zoom">
                <h2>可迁移性</h2>
                <hr>
                <p style="font-size: 30px;">对抗样本可以在不同网络结构上迁移性</p>
                <img src="https://s2.loli.net/2022/05/13/n45NscrjOXYpdEM.png" style="width: 700px;height: 300px;">
            </section>
            <aside class="notes">
                可转移性指的是一个对抗样本具有可转移能力，即使是除了用来产生它的模型以外，它仍然有效
            </aside>
        </section>

        <section data-background-transition="zoom">
            <section data-background-transition="zoom">
                <h2>对抗样本产生原因讨论</h2>
                <hr>
                <p style="font-size: 30px;">神经网络偏好纹理(高频)而不是轮廓(低频)？</p>
                <img src="https://s2.loli.net/2022/05/13/28Hh5kLrDIXWwjB.png" style="width: 700px;height: 300px;">
            </section>
            <aside class="notes">
                
            </aside>

            <section data-background-transition="zoom">
                <h2>对抗样本产生原因讨论</h2>
                <hr>
                <p style="font-size: 30px;">对抗训练的神经网络更关注轮廓特征？</p>
                <img src="https://s2.loli.net/2022/05/13/dmcGujzpHf1oBLy.png" style="width: 700px;height: 400px;">
            </section>
            <aside class="notes">
            </aside>

            <section data-background-transition="zoom">
                <h2>对抗样本产生原因讨论</h2>
                <hr>
                <p style="font-size: 30px;">神经网络和人眼关注的图像特征不同？</p>
                <img src="https://s2.loli.net/2022/05/13/adu1bRTE9OrzSxm.png" style="width: 700px;height: 300px;">
            </section>
            <aside class="notes">
                图中最左边是一个干净的狗的图片，它包含狗的鲁棒特征和狗的非鲁棒特征。经过对猫这个类进行针对性攻击，得到错误分类的狗的图片，这时生成的对抗图片包含狗的鲁棒特征（人眼看起来是狗） 和猫的非鲁棒特征（网络认为是猫）。然后把生成的对抗图片错误标记为猫这个类，丢入网络进行训练，最后得到的模型在未经过干净的猫的训练情况下，在干净的猫的图片上也有很好的准确度。这个实验证明神经网络识别图片的方式与人眼不同，它们依靠图片上的人眼不易察觉的非鲁棒特征去识别图片。 
            </aside>

        </section>



        <section data-background-transition="zoom">
            <h2>谢谢</h2>
            <!-- <a href="https://github.com/Coding-Zuo" target="_blank">Github</a><br>
            <a href="https://coding-zuo.github.io/" target="_blank">Blog</a> -->
            <aside class="notes">

            </aside>
        </section>
    </div>
</div>

<script src="lib/js/head.min.js"></script>
<script src="js/reveal.js"></script>

<script>
    // More info about config & dependencies:
    // - https://github.com/hakimel/reveal.js#configuration
    // - https://github.com/hakimel/reveal.js#dependencies
    Reveal.initialize({
        math: {
            mathjax: 'plugin/MathJax.js',
            config: 'TeX-AMS_HTML-full'  // 参考 http://docs.mathjax.org/en/latest/config-files.html
        },
        dependencies: [
            {src: 'plugin/markdown/marked.js'},
            {src: 'plugin/markdown/markdown.js'},
            {src: 'plugin/notes/notes.js', async: true},
            {
                src: 'plugin/highlight/highlight.js', async: true, callback: function () {
                    hljs.initHighlightingOnLoad();
                }
            },
            {src: 'plugin/math/math.js', async: true}
        ]

    });
</script>
</body>
</html>
